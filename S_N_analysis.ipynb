{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4e454f8-35f0-4416-a85c-5cd41fe3a9a7",
   "metadata": {},
   "source": [
    "# Future scenario S/N ratio analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064732b9-05db-4c2a-8678-6ef2bed44682",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mamba install -y --file /home/jovyan/pangeo/code/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a270e-655b-4274-9977-31a17617ae0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask\n",
    "from dask.diagnostics import progress\n",
    "from tqdm.autonotebook import tqdm \n",
    "import intake\n",
    "import fsspec\n",
    "import seaborn as sns\n",
    "#import esmvalcore.preprocessor as ecpr\n",
    "#import pymannkendall as mkt\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74515a5e-e410-4018-9712-edf56bf7dea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = intake.open_esm_datastore(\"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\")\n",
    "col\n",
    "\n",
    "# there is currently a significant amount of data for these runs\n",
    "expts_full = ['historical','ssp126', 'ssp245', 'ssp370', 'ssp585', 'piControl']\n",
    "\n",
    "query = dict(\n",
    "    #activity_id = 'DAMIP',\n",
    "    experiment_id=expts_full,\n",
    "    table_id='Amon',                           \n",
    "    variable_id=['tas', 'pr', 'ua', 'va'],\n",
    "    member_id = 'r1i1p1f1',                     \n",
    ")\n",
    "\n",
    "col_subset = col.search(require_all_on='source_id', **query)\n",
    "#col_subset.df = col_subset.df[col_subset.df['source_id'] != 'FGOALS-f3-L']\n",
    "col_subset_var = [col_subset.search(variable_id=var_name) for var_name in query['variable_id']]\n",
    "print(f'Number of models found: {col_subset.df.source_id.nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a801b5-76b7-4f5c-a841-9d47c6661fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6234f0d1-5c8e-491a-9b4e-1e1cde85481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_all_bounds(ds):\n",
    "    drop_vars = [vname for vname in ds.coords\n",
    "                 if (('_bounds') in vname ) or ('_bnds') in vname]\n",
    "    return ds.drop(drop_vars)\n",
    "\n",
    "def open_dset(df):\n",
    "    #assert len(df) == 1\n",
    "    ds = xr.open_zarr(fsspec.get_mapper(df.zstore.values[0]), consolidated=True, decode_times=True, use_cftime=True)\n",
    "    if 'plev' in ds.coords:\n",
    "        for lev in ds.plev.values:\n",
    "            if int(lev)==85000:\n",
    "                ind = np.where(ds.plev.values==lev)\n",
    "                break\n",
    "        ds = ds.isel(plev=ind[0]).drop('plev')\n",
    "        #ds.drop('plev')\n",
    "    return drop_all_bounds(ds)\n",
    "\n",
    "def open_delayed(df):\n",
    "    return dask.delayed(open_dset)(df)\n",
    "\n",
    "from collections import defaultdict\n",
    "dsets = []\n",
    "for col_subset in col_subset_var :\n",
    "    dset = defaultdict(dict)\n",
    "\n",
    "    for group, df in col_subset.df.groupby(by=['source_id', 'experiment_id']):\n",
    "        dset[group[0]][group[1]] = open_delayed(df)\n",
    "    dsets.append(dset)\n",
    "len(dsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e104e35e-c9ef-49d3-bf90-4a481e510ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with progress.ProgressBar():\n",
    "    dsets_ = [dask.compute(dict(dset))[0] for dset in dsets[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fac7182-18f8-487a-a4e1-3acefaceb7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_dict = col_subset_var[3].to_dataset_dict(\n",
    "    zarr_kwargs={\"consolidated\": True, \"decode_times\": True, \"use_cftime\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a8c092-8b16-478a-b263-035dd7188e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = [key for key in dset_dict.keys()]\n",
    "dset_dict[ss[10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4229f8da-81d0-4f54-9832-9862e8c3305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymannkendall as mkt\n",
    "import esmvalcore.preprocessor as ecpr\n",
    "import dask.array as da\n",
    "import iris\n",
    "import itertools\n",
    "import xesmf as xe\n",
    "def get_vname(ds):\n",
    "    #print(ds.variables)\n",
    "    for v_name in ds.variables.keys():\n",
    "        #print(v_name)\n",
    "        if v_name in ['pr', 'ua', 'va']:\n",
    "            return v_name\n",
    "    raise RuntimeError(\"Couldn't find a variable\")\n",
    "            \n",
    "def get_lat_name(ds):\n",
    "    for lat_name in ['lat', 'latitude']:\n",
    "        if lat_name in ds.coords:\n",
    "            return lat_name\n",
    "    raise RuntimeError(\"Couldn't find a latitude coordinate\")\n",
    "    \n",
    "def get_lon_name(ds):\n",
    "    for lon_name in ['lon', 'longitude']:\n",
    "        if lon_name in ds.coords:\n",
    "            return lon_name\n",
    "    raise RuntimeError(\"Couldn't find a longitude coordinate\")\n",
    "\n",
    "def regrid(ds):\n",
    "    var_name = get_vname(ds)\n",
    "    lat_name = get_lat_name(ds)\n",
    "    lon_name = get_lon_name(ds)\n",
    "    \n",
    "    ds_out = xr.Dataset({\n",
    "        lat_name: ([lat_name], np.arange(-90, 90, 1.0)),\n",
    "        lon_name: ([lon_name], np.arange(-180, 180, 1.0)),\n",
    "    })\n",
    "    regridder = xe.Regridder(ds, ds_out, 'bilinear')\n",
    "    ds_reg = regridder(ds)#.to_dataset(name=var_name)\n",
    "    ds_reg = ds_reg.sel({lat_name:slice(-40, 40), lon_name:slice(5,120)})\n",
    "    return ds_reg\n",
    "\n",
    "\n",
    "def jjas_mean(ds):\n",
    "    #print(ds)\n",
    "    var_name = get_vname(ds)\n",
    "    lat_name = get_lat_name(ds)\n",
    "    lon_name = get_lon_name(ds)\n",
    "    mind = ds.groupby('time.month')\n",
    "    mind_sel = mind.groups[6] + mind.groups[7] + mind.groups[8] + mind.groups[9] \n",
    "    ds_sel = ds[var_name][mind_sel].groupby('time.year').mean().to_dataset(name=var_name)\n",
    "    #print(ds_sel)\n",
    "    return ds_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7e0282-6b7d-43c2-9096-75896743a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz.functoolz import juxt\n",
    "expt_norm = expts_full[:-1]\n",
    "expt_da = xr.DataArray(expt_norm, dims='experiment_id', name='experiment_id',\n",
    "                       coords={'experiment_id': expt_norm})\n",
    "\n",
    "dsets_aligned_list = []\n",
    "\n",
    "##selecting variable 'pr' only\n",
    "\n",
    "for dset_ in dsets_:\n",
    "    j=0\n",
    "    dsets_aligned = {}\n",
    "    for k, v in tqdm(dset_.items()):\n",
    "        #print(k)\n",
    "        expt_dsets = v.values()\n",
    "        if any([d is None for d in expt_dsets]):\n",
    "            print(f\"Missing experiment for {k}\")\n",
    "            continue\n",
    "\n",
    "        # workaround for\n",
    "        # https://github.com/pydata/xarray/issues/2237#issuecomment-620961663\n",
    "        dsets_jjas_mean = []\n",
    "        for expt in expt_norm:\n",
    "            ds = v[expt].pipe(regrid).pipe(jjas_mean)\n",
    "            if expt == 'historical':\n",
    "                ds = ds.sel(year=slice(1950,2014))\n",
    "            dsets_jjas_mean.append(ds)\n",
    "\n",
    "        # align everything with the 4xCO2 experiment\n",
    "\n",
    "        dsets_aligned[k] = xr.concat(dsets_jjas_mean, join='outer',\n",
    "                                    dim=expt_da)\n",
    "    dsets_aligned_list.append(dsets_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f8017-6b81-4d41-8cba-986551d5435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with progress.ProgressBar():\n",
    "    dsets_aligned_list_1 = dask.compute(dsets_aligned_list[0])[0]\n",
    "\n",
    "with progress.ProgressBar():\n",
    "    dsets_aligned_list_2 = dask.compute(dsets_aligned_list[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6b6393-84ab-4c49-89ae-461896518ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets_aligned_list_ = [dsets_aligned_list_1, dsets_aligned_list_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2512ef68-6406-4ac9-b9da-123b164693bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ids = [list(dl.keys()) for dl in dsets_aligned_list_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5406fa-45a1-4c3c-9ea5-10e42fa3886a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_ds = []\n",
    "for idx, sid_ls in enumerate(source_ids):\n",
    "    source_da = xr.DataArray(sid_ls, dims='source_id', name='source_id',\n",
    "                             coords={'source_id': sid_ls})\n",
    "    wind_ds.append(xr.concat([ds.reset_coords(drop=True)\n",
    "                        for ds in dsets_aligned_list_[idx].values()],\n",
    "                        dim=source_da))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede21c6a-2c5b-4c42-aae7-7e3e18416f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_dss = xr.merge(wind_ds)\n",
    "wind_dss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46335fcb-a5c0-42b3-8118-600fb4b8e91e",
   "metadata": {},
   "source": [
    "## S/N ratio analysis\n",
    "focus on two future periods one up to the 2050s \n",
    "\n",
    "    -  2025 to 2055, and\n",
    "    -  2069 to 2099. \n",
    "    - Do the analysis focusing on Asian summer monsoon rainfall (also using MME but better to check for model spread) \n",
    "    and for different scenario SSPs 1-1.9, 2-4.5, 3-7.0, and 5-8.5. \n",
    "    \n",
    "    - What would be the signal to noise ratio (MME future change/ Inter model SD) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786f075f-cbaa-40e0-be83-9990075cfa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_ds = xr.open_dataset('/home/jovyan/pangeo/data/jjas_pr.nc') ###this file does not exist in this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f32535f-9f4f-4d1c-9480-5b1fa36d2649",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data = wind_dss.sel({'experiment_id':'historical', 'year':slice(1985,2014),}).mean('year')\n",
    "hist_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1f0478-20f2-4e04-8404-e1d4b6795269",
   "metadata": {},
   "outputs": [],
   "source": [
    "near_future = big_ds.sel(experiment_id=(wind_dss.experiment_id != 'historical'), year=slice(2025, 2055))\n",
    "nf_mean = near_future.mean('year')\n",
    "nf_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd4130-7055-48be-94f5-a28ef5597aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "far_future = big_ds.sel(experiment_id=(wind_dss.experiment_id != 'historical'), year=slice(2069, 2099))\n",
    "ff_mean = far_future.mean('year')\n",
    "ff_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb5b5e-e9bc-48a1-b46b-158be5c44775",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_change = nf_mean - hist_data\n",
    "nf_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc479765-44d3-4868-90de-13bc84c0f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_change = ff_mean - hist_data\n",
    "ff_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d9cad5-710a-4122-850d-e11fd4f809cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_ens = nf_change.mean('source_id')\n",
    "nf_std = nf_change.std('source_id')\n",
    "nf_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4232daf-f112-4cb2-864a-49caac8f9bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_ens = ff_change.mean('source_id')\n",
    "ff_std = ff_change.std('source_id')\n",
    "ff_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95855b4d-8b9e-45d7-bdeb-bf8847570a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "nf_sn = nf_ens/nf_std\n",
    "abs(nf_sn).plot(col='experiment_id', vmin=0, vmax=2, cmap='RdYlGn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b50d26-e697-4c6c-bb67-658ccda6b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_sn = ff_ens / ff_std\n",
    "#ff_sn.pr.plot(col='experiment_id', cmap='rainbow', vmin=-2, vmax=2)\n",
    "ff_sn.plot(col='experiment_id', vmin=-5, vmax=5, cmap='seismic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23242f01-7e42-44d8-b587-f643a21201c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from cartopy import feature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.colorbar as clb\n",
    "import itertools\n",
    "\n",
    "change_arr = [nf_ens, ff_ens]\n",
    "sd_arr = [nf_std, ff_std]\n",
    "snr_arr = [nf_sn, ff_sn]\n",
    "\n",
    "nrow = 3\n",
    "ncol = 4\n",
    "\n",
    "\n",
    "k=0\n",
    "arrs = [change_arr[k], sd_arr[k], snr_arr[k]]\n",
    "cbar_title = ['Future change: ms$^{-1}$', 'Standard Deviation: ms$^{-1}$', 'S/N ratio']\n",
    "sup_title = [\"Near future (2025-2055) wind (850hPa) relative to climatology 1985-2014\", \n",
    "             \"Far future (2069-2099) wind (850hPa) relative to climatology 1985-2014\" ]\n",
    "cmaps = ['seismic', 'hot_r', 'RdYlGn']\n",
    "\n",
    "ff_lim = [np.linspace(-1.4, 1.4, 15), np.linspace(0, 1.2, 7), np.linspace(-1.6, 1.6, 17)]\n",
    "nf_lim = [np.linspace(-1.4, 1.4, 15), np.linspace(0, 1.2, 7), np.linspace(-1.6, 1.6, 17)]\n",
    "lim_arr = [nf_lim, ff_lim]\n",
    "\n",
    "cbar_y = 0.65\n",
    "fig, axs = plt.subplots(nrow, ncol, dpi=300, \n",
    "                        subplot_kw={'projection': ccrs.PlateCarree()}, \n",
    "                        figsize= (12,7))\n",
    "fig.suptitle(sup_title[k], x=0.55, y=0.95, fontsize=16, weight='bold')\n",
    "\n",
    "for i in range(nrow):\n",
    "    data = arrs[i]\n",
    "    X,Y = np.meshgrid(data.lon, data.lat)\n",
    "    for j in range(ncol):\n",
    "        ax = axs[i,j]\n",
    "        ax.coastlines()\n",
    "        \n",
    "        gl = ax.gridlines(crs=ccrs.PlateCarree(), linewidth=2, color='grey', \n",
    "                          alpha=0.3, linestyle='-', draw_labels=True)\n",
    "        fs=8\n",
    "        gl.top_labels = False\n",
    "        gl.right_labels = False\n",
    "        gl.xformatter = LONGITUDE_FORMATTER\n",
    "        gl.yformatter = LATITUDE_FORMATTER\n",
    "        gl.xlabel_style = {'size': fs}\n",
    "        gl.ylabel_style = {'size': fs}\n",
    "        \n",
    "        pc = ax.contourf(X, Y, data.squeeze().isel(experiment_id=j), cmap=cmaps[i], extend='both', levels=lim_arr[k][i])\n",
    "        #if i==2:\n",
    "        #    for x in range(len(data.lon)):\n",
    "        #        for y in range(len(data.lat)):\n",
    "        #            if abs(data.pr[j, y, x].values) > 1:\n",
    "        #                xx,yy = X[y, x], Y[y, x]\n",
    "        #                ax.plot(xx, yy, '.', markersize=0.5, color='k')\n",
    "        bbox = [10,120,-20,40]\n",
    "        #ax.set_extent(bbox,crs=ccrs.PlateCarree())\n",
    "        if i==0:\n",
    "            ax.set_title(data.experiment_id.isel(experiment_id=j).values, fontsize=12, weight='bold')\n",
    "    \n",
    "    clb_ax_params = [0.92, cbar_y, 0.009, 0.23]\n",
    "    cbar_y = cbar_y - 0.27\n",
    "    cbar_ax = fig.add_axes(clb_ax_params)\n",
    "    cb = fig.colorbar(pc, cax=cbar_ax, orientation='vertical')\n",
    "    cb.ax.tick_params(labelsize=8)\n",
    "    cbar_ax.set_ylabel(cbar_title[i], size=9)\n",
    "    \n",
    "path = ['/home/jovyan/pangeo/plot/near_future_wind.png', '/home/jovyan/pangeo/plot/far_future_wind.png']\n",
    "plt.savefig(path[k], bbox_inches='tight', facecolor='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17d6930-12ed-45e2-b226-e08e29e363ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8276b73a-1946-4df0-a8c3-8f499cc70c0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6161728a-be83-4ee4-a8c8-70ced5fdad64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
