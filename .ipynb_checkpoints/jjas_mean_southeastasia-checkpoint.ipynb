{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9871155a-7646-4d82-be5e-3fbd9527ffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import xesmf as xe\n",
    "import cartopy\n",
    "import dask\n",
    "from tqdm.autonotebook import tqdm  # Fancy progress bars for our loops!\n",
    "from dask.diagnostics import progress\n",
    "import intake\n",
    "import fsspec\n",
    "\n",
    "%matplotlib inline\n",
    "#plt.rcParams['figure.figsize'] = 12, 6\n",
    "%config InlineBackend.figure_format = 'retina' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2cfb28-48da-4299-9730-671a5a50f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = intake.open_esm_datastore(\"https://storage.googleapis.com/cmip6/pangeo-cmip6.json\")\n",
    "col\n",
    "expts_full = ['historical','ssp126', 'ssp245', 'ssp370', 'ssp585', 'piControl']\n",
    "\n",
    "query = dict(\n",
    "    experiment_id=expts_full, # pick the `abrupt-4xCO2` and `piControl` forcing experiments\n",
    "    table_id='Amon',                            # choose to look at atmospheric variables (A) saved at monthly resolution (mon)\n",
    "    variable_id=['tas', 'pr','ua', 'va'],  # choose to look at near-surface air temperature (tas) as our variable\n",
    "    #level=[850]\n",
    "    member_id = 'r1i1p1f1',                     # arbitrarily pick one realization for each model (i.e. just one set of initial conditions)\n",
    ")\n",
    "\n",
    "col_subset = col.search(require_all_on=[\"source_id\"], **query)\n",
    "col_subset_var = [col_subset.search(variable_id=var_name) for var_name in query['variable_id']]\n",
    "col_subset.df[['source_id', 'experiment_id', 'variable_id', 'member_id']].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b987d640-f13e-42fc-a6f5-07fbc15f75a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_all_bounds(ds):\n",
    "    drop_vars = [vname for vname in ds.coords\n",
    "                 if (('_bounds') in vname ) or ('_bnds') in vname]\n",
    "    return ds.drop(drop_vars)\n",
    "\n",
    "def open_dset(df):\n",
    "    #assert len(df) == 1\n",
    "    ds = xr.open_zarr(fsspec.get_mapper(df.zstore.values[0]), consolidated=True, decode_times=True, use_cftime=True)\n",
    "    if 'plev' in ds.coords:\n",
    "        for lev in ds.plev.values:\n",
    "            if int(lev)==85000:\n",
    "                ind = np.where(ds.plev.values==lev)\n",
    "                break\n",
    "        ds = ds.isel(plev=ind[0]).drop('plev')\n",
    "        #ds.drop('plev')\n",
    "    return drop_all_bounds(ds)\n",
    "\n",
    "def open_delayed(df):\n",
    "    return dask.delayed(open_dset)(df)\n",
    "\n",
    "from collections import defaultdict\n",
    "dsets = []\n",
    "for col_subset in col_subset_var :\n",
    "    dset = defaultdict(dict)\n",
    "\n",
    "    for group, df in col_subset.df.groupby(by=['source_id', 'experiment_id']):\n",
    "        dset[group[0]][group[1]] = open_delayed(df)\n",
    "    dsets.append(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c87f70-d879-4f3f-aabe-60ff1964510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets_ = [dask.compute(dict(dset))[0]for dset in dsets[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff1bde6-ced9-451f-bc5b-ef52d5c665dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymannkendall as mkt\n",
    "import esmvalcore.preprocessor as ecpr\n",
    "import dask.array as da\n",
    "import iris\n",
    "import numpy as np\n",
    "from cf_units import Unit\n",
    "import itertools\n",
    "def get_vname(ds):\n",
    "    #print(ds.variables)\n",
    "    for v_name in ds.variables.keys():\n",
    "        #print(v_name)\n",
    "        if v_name in ['pr', 'ua', 'va']:\n",
    "            return v_name\n",
    "    raise RuntimeError(\"Couldn't find a variable\")\n",
    "            \n",
    "def get_lat_name(ds):\n",
    "    for lat_name in ['lat', 'latitude']:\n",
    "        if lat_name in ds.coords:\n",
    "            return lat_name\n",
    "    raise RuntimeError(\"Couldn't find a latitude coordinate\")\n",
    "    \n",
    "def get_lon_name(ds):\n",
    "    for lon_name in ['lon', 'longitude']:\n",
    "        if lon_name in ds.coords:\n",
    "            return lon_name\n",
    "    raise RuntimeError(\"Couldn't find a longitude coordinate\")\n",
    "\n",
    "def regrid(ds):\n",
    "    var_name = get_vname(ds)\n",
    "    #print(var_name)\n",
    "    ds = ds[var_name]\n",
    "    #ds_out = xe.util.grid_2d(-180.0, 180.0, 1.0, -90.0, 90.0, 1.0)\n",
    "    ds_out = xr.Dataset({\n",
    "        \"lat\": ([\"lat\"], np.arange(-90, 90, 1.0)),\n",
    "        \"lon\": ([\"lon\"], np.arange(-180, 180, 1.0)),\n",
    "    })\n",
    "    regridder = xe.Regridder(ds, ds_out, 'bilinear')\n",
    "    ds_reg = regridder(ds).to_dataset(name=var_name)\n",
    "    return ds_reg\n",
    "\n",
    "\n",
    "\n",
    "def jjas_mean(ds):\n",
    "    #print(ds)\n",
    "    var_name = get_vname(ds)\n",
    "    lat_name = get_lat_name(ds)\n",
    "    lon_name = get_lon_name(ds)\n",
    "    mind = ds.groupby('time.month')\n",
    "    mind_sel = mind.groups[6] + mind.groups[7] + mind.groups[8] + mind.groups[9] \n",
    "    ds_sel = ds[var_name][mind_sel].groupby('time.year').mean().sel({'year':slice(1950,2014), lat_name:slice(-40, 40), lon_name:slice(5,120)}).mean(dim='year')\n",
    "    return ds_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15014782-175f-4e9d-8ba8-bf4c2eb212c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolz.functoolz import juxt\n",
    "expts = expts_full[0]\n",
    "#expt_da = xr.DataArray(expts, dims='experiment_id', name='experiment_id',\n",
    "#                       coords={'experiment_id': expts})\n",
    "\n",
    "dsets_aligned_list = []\n",
    "for dset_ in dsets_:\n",
    "    dsets_aligned = {}\n",
    "    for k, v in tqdm(dset_.items()):\n",
    "\n",
    "        expt_dsets = v.values()\n",
    "        if any([d is None for d in expt_dsets]):\n",
    "            print(f\"Missing experiment for {k}\")\n",
    "            continue\n",
    "\n",
    "        # workaround for\n",
    "        # https://github.com/pydata/xarray/issues/2237#issuecomment-620961663\n",
    "        dsets_ann_mean = v[expts].pipe(regrid).pipe(jjas_mean)\n",
    "\n",
    "        # align everything with the 4xCO2 experiment\n",
    "\n",
    "        dsets_aligned[k] = dsets_ann_mean\n",
    "    dsets_aligned_list.append(dsets_aligned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f12ede-11d2-40a1-ba20-376867760d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with progress.ProgressBar():\n",
    "    dsets_aligned_list_1 = dask.compute(dsets_aligned_list[0])[0]\n",
    "        \n",
    "with progress.ProgressBar():\n",
    "    dsets_aligned_list_2 = dask.compute(dsets_aligned_list[1])[0]\n",
    "    \n",
    "with progress.ProgressBar():\n",
    "    dsets_aligned_list_3 = dask.compute(dsets_aligned_list[2])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07353635-68de-4f90-aca7-94ea866bc5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets_algned_list_ = [dsets_aligned_list_1, dsets_aligned_list_2, dsets_aligned_list_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef74674-1fd6-4e2e-af25-6ec308155c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ids = [list(dsets_aligned_.keys()) for dsets_aligned_ in dsets_algned_list_]\n",
    "#source_da = xr.DataArray(source_ids, dims='source_id', name='source_id',\n",
    "#                         coords={'source_id': source_ids})\n",
    "big_ds_wind = []\n",
    "for idx, dsets_aligned_ in enumerate(dsets_algned_list_[1:]):\n",
    "    source_da = xr.DataArray(source_ids[idx+1], dims='source_id', name='source_id',\n",
    "                         coords={'source_id': source_ids[idx+1]})\n",
    "    big_ds_wind.append(xr.concat([ds.reset_coords(drop=True)\n",
    "                        for ds in dsets_aligned_.values()],\n",
    "                        dim=source_da))\n",
    "\n",
    "source_da = xr.DataArray(source_ids[0], dims='source_id', name='source_id',\n",
    "                         coords={'source_id': source_ids[0]})\n",
    "big_ds_pr = xr.concat([ds.reset_coords(drop=True)\n",
    "                    for ds in dsets_algned_list_[0].values()],\n",
    "                    dim=source_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f363db82-b192-47ac-955d-31eada4c2f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = (big_ds_pr*86400).isel(source_id=0).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff9ab15-c535-4e03-9c39-8df1a6d3640e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all = xr.merge([ds for ds in big_ds_wind])\n",
    "ds_all.to_netcdf('/home/jovyan/pangeo/data/wind_jjas_mean_1950_2014.nc')\n",
    "ds_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1803ba2-56a3-443e-8377-35975205416f",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_ds_pr.to_netcdf('/home/jovyan/pangeo/data/pr_jjas_mean_1950_2014.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31e1558-6ff3-4098-97c2-f224d8f50d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_mmm = (big_ds_pr*86400).mean(dim='source_id')\n",
    "ds_wind_mmm = ds_all.squeeze().mean(dim='source_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d61bf9d-e486-4037-b319-aa37ba32a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "ucube = ds_wind_mmm.ua.rename({'lat':'latitude', 'lon':'longitude'}).to_iris()\n",
    "ulat = ucube.coord(\"latitude\")\n",
    "ulon = ucube.coord(\"longitude\")\n",
    "\n",
    "\n",
    "ulat.standard_name = \"latitude\"\n",
    "ulon.standard_name = \"longitude\"\n",
    "#usource.standard_name = \"model\"\n",
    "\n",
    "\n",
    "ucube.remove_coord(\"latitude\")\n",
    "ucube.add_dim_coord(ulat, 0)\n",
    "ucube.remove_coord(\"longitude\")\n",
    "ucube.add_dim_coord(ulon, 1)\n",
    "\n",
    "dsu  = xr.DataArray.from_iris(ecpr.mask_landsea(ucube, 'land'))\n",
    "\n",
    "##################################################\n",
    "vcube = ds_wind_mmm.va.rename({'lat':'latitude', 'lon':'longitude'}).to_iris()\n",
    "ulat = vcube.coord(\"latitude\")\n",
    "ulon = vcube.coord(\"longitude\")\n",
    "\n",
    "ulat.standard_name = \"latitude\"\n",
    "ulon.standard_name = \"longitude\"\n",
    "\n",
    "vcube.remove_coord(\"latitude\")\n",
    "vcube.add_dim_coord(ulat, 0)\n",
    "vcube.remove_coord(\"longitude\")\n",
    "vcube.add_dim_coord(ulon, 1)\n",
    "\n",
    "dsv = xr.DataArray.from_iris(ecpr.mask_landsea(vcube, 'land'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e759b0aa-45d6-4996-bc8e-d111c9f13243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from cartopy import feature\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.colorbar as clb\n",
    "import itertools\n",
    "import esmvalcore.preprocessor as ecpr\n",
    "\n",
    "fig = plt.figure(dpi=400, figsize=(10,10))\n",
    "ax = plt.subplot(projection=ccrs.PlateCarree())\n",
    "\n",
    "X,Y = np.meshgrid(pr_mmm.lon, pr_mmm.lat)\n",
    "\n",
    "ax.coastlines()\n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), linewidth=2, color='grey', \n",
    "                  alpha=0.3, linestyle='-', draw_labels=True)\n",
    "fs=10\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'size': fs}\n",
    "gl.ylabel_style = {'size': fs}\n",
    "\n",
    "lim=10\n",
    "pc = ax.contourf(X, Y, pr_mmm, cmap='Spectral_r', extend='both', levels=np.linspace(0, lim, 21))\n",
    "\n",
    "skip = 3\n",
    "qv = ax.quiver(X[::skip,::skip], Y[::skip,::skip], \n",
    "                dsu[::skip, ::skip],\n",
    "                dsv[::skip, ::skip],\n",
    "                scale=160, scale_units='width', pivot='middle',\n",
    "                width=0.002, headwidth = 4)\n",
    "\n",
    "ax.quiverkey(qv, 0.82, 0.71, 5, label= r'$5 \\frac{m}{s}$ ',\n",
    "                          coordinates='figure')\n",
    "cax,kw = clb.make_axes(ax,location='right',pad=0.05,shrink=0.5,fraction=0.09,aspect=18)\n",
    "cbar = fig.colorbar(pc,cax=cax,**kw)\n",
    "cbar.ax.tick_params(labelsize=10)\n",
    "cbar.ax.set_ylabel('pr: mm/day', size=12, weight='bold')\n",
    "ax.set_title(\"JJAS mean precipitation and wind (850 hPa) 1950-2014 \\n Multi model mean\", fontsize=18, weight='bold')\n",
    "fig.savefig('/home/jovyan/pangeo/plot/jjas_pr_wind_850_mmm_1950_2014.png', bbox_inches='tight', facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bfb66a-0e16-4a98-bfb9-4c3e5db31bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43885043-6c9e-4699-b68d-934e211d2de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
